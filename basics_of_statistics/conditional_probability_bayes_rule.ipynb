{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a random experiment modeled by a probability space $(S, \\mathscr{S} , \\mathbb{P})$. Thus, $S$ is the set of outcomes, $\\mathscr{S}$ the collection of events, and $\\mathbb{P}$ the probability measure on the sample space $(S, \\mathscr{S})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition.** Let $A$ and $B$ be events with $\\mathbb{P}(B) > 0$. The **conditional probability** of $A$ given $B$ is defined to be\n",
    "\n",
    "$$\\mathbb{P}(A \\mid B) = \\frac{\\mathbb{P}(A \\cap B)}{ \\mathbb{P}(B)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that $\\mathcal{A} = \\{ A_i \\mid i \\in I \\}$ is a countable collection of events that partition the sample space $S$, and that $\\mathbb{P}(A_i) > 0$ for each $i \\in I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Law of total probability.** If $B$ is an event then\n",
    "\n",
    "$$\\mathbb{P}(B) = \\sum_{i \\in I} \\mathbb{P}(A_i) \\mathbb{P}(B \\mid A_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayes' theorem.** If $B$ is an event then\n",
    "\n",
    "$$\\mathbb{P}(A_j \\mid B) = \\frac{\\mathbb{P}(A_j) \\mathbb{P}(B \\mid A_j)}{\\sum_{i \\in I} \\mathbb{P}(A_i) \\mathbb{P}(B \\mid A_i)}, \\ j \\in I.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diagnostic Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have a random experiment with an event $A$ of interest. When we run the experiment, of course, event $A$ will either occur or not occur. However, suppose that we are not able to observe the occurence or non-occurence of $A$ directly. Instead we have a **diagnostic test**  designed to indicate the occurrence of event $A$; thus the test that can be either **positive** for $A$ or **negative** for $A$. The test also has an element of randomness, and in particular can be in error. Here are some typical examples of the type of situation we have in mind:\n",
    "\n",
    "- The event is that a person has a certain diesease and the test is a blood test for the disease.\n",
    "\n",
    "- The event is that a woman is pregnant and the test is a home pregnancy test.\n",
    "\n",
    "- The event is that a device is defective and the test consists of a sensor reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $T$ be the event that the test is positive for the occurrence of $A$. The conditional probability $\\mathbb{P}(T \\mid A)$ is called the **sensitivity** of the test. The complementary probability\n",
    "\n",
    "$$\\mathbb{P}(T^c \\mid A) = 1 - \\mathbb{P}(T \\mid A)$$\n",
    "\n",
    "is the **false negative** probability. The conditional probability $\\mathbb{P}(T^c \\mid A^c)$ is called the **specificity** of the test. The complementary probability\n",
    "\n",
    "$$\\mathbb{P}(T \\mid A^c) = 1 - \\mathbb{P}(T^c \\mid A^c)$$\n",
    "\n",
    "is the **false positive** probability. In many cases, the sensitivity and specificity of the test are known, as a result of the development of the test. However, the user of the test is interested in the opposite conditional probabilities, namely $\\mathbb{P}(A \\mid T)$, the probability of the event of interest, given a positive positive test, and $\\mathbb{P}(A^c \\mid T^c)$ , the probability of the complementary event, given a negative test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the probabilities of interest is simply a special case of Bayes' theorem. The probability that the event occurs, given a positive test is\n",
    "\n",
    "$$ \\mathbb{P}(A \\mid T) = \\frac{\\mathbb{P}(A)\\mathbb{P}(T \\mid A)}{\\mathbb{P}(A)\\mathbb{P}(T \\mid A)+\\mathbb{P}(A^c)\\mathbb{P}(T \\mid A^c)}$$\n",
    "\n",
    "The probability that the event does not occur, given a negative test is\n",
    "\n",
    "$$ \\mathbb{P}(A^c \\mid T^c) = \\frac{\\mathbb{P}(A^c)\\mathbb{P}(T^c \\mid A^c)}{\\mathbb{P}(A)\\mathbb{P}(T^c \\mid A)+\\mathbb{P}(A^c)\\mathbb{P}(T^c \\mid A^c)}$$\n",
    "\n",
    "There is often a trade-off between sensitivity and specificity. An attempt to make a test more sensitive may result in the test being less specific, and an attempt to make a test more specific may result in the test being less sensitive.\n",
    "\n",
    "As an extreme example, consider the worthless test that always returns positive, no matter what the evidence. Then $T=S$ so the test has sensitivity $1$, but specificity $0$. At the opposite extreme is the worthless test that always returns negative, no matter what the evidence. Then $T = \\emptyset$ so the test has specificity $1$ but sensitivity $0$. In between these extremes are helpful tests that are actually based on evidence of some sort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Suppose that a diagnostic test has sensitivity $0.99$ and specificity $0.95$. Then for $\\mathbb{P}(A) = 0.001$, one calculates that $\\mathbb{P}(A \\mid T) \\approx 0.0194$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
